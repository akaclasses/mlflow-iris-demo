"""
Classification d'iris - MÃ©thode classique (sans MLflow)
Le scientifique dÃ©sorganisÃ© qui ne note rien ! ğŸ”¬
"""
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import pickle
import os
from datetime import datetime

print("ğŸ”¬ ExpÃ©rience ML classique - MÃ©thode 'artisanale'")
print(f"ğŸ“… Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# ParamÃ¨tres (cachÃ©s dans le code, pas documentÃ©s)
n_estimators = 15  # Pourquoi 15 ?
max_depth = 3      # Profondeur max des arbres, mais pourquoi 3 ?
test_size = 0.30   # TestÃ© plusieurs valeurs, mais laquelle Ã©tait la meilleure ?
random_seed = 42   # Toujours 42, mais pourquoi ?

print(f"ğŸ§ª Test avec {n_estimators} arbres, profondeur {max_depth}, split {test_size}")

# 1. DonnÃ©es (d'oÃ¹ viennent-elles ?)
iris = datasets.load_iris()  # Dataset iris intÃ©grÃ© Ã  scikit-learn
X, y = iris.data, iris.target
print(f"ğŸ“Š DonnÃ©es: {len(X)} Ã©chantillons, {X.shape[1]} caractÃ©ristiques")
print(f"ğŸ¯ Classes: {iris.target_names}")

# 2. Division train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=test_size, random_state=random_seed
)

# 3. EntraÃ®nement
model = RandomForestClassifier(
    n_estimators=n_estimators, 
    max_depth=max_depth,
    random_state=random_seed
)
model.fit(X_train, y_train)

# 4. Ã‰valuation
predictions = model.predict(X_test)
accuracy = accuracy_score(y_test, predictions)

# 5. Sauvegarde "artisanale"
model_filename = f"iris_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
with open(model_filename, 'wb') as f:
    pickle.dump(model, f)

print(f"âœ… PrÃ©cision: {accuracy:.2%}")
print(f"ğŸ’¾ ModÃ¨le sauvÃ©: {model_filename}")